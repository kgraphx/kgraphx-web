<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Building Covid19 Q&amp;A System Demo with Haystack Framework</title>
      <link href="/2021/11/18/haystack-covid/"/>
      <url>/2021/11/18/haystack-covid/</url>
      
        <content type="html"><![CDATA[<p><img src="images/covid19qa.jpg" alt="cover"></p><p><strong>Demonstration</strong><br><a href="http://49.232.0.204/">http://49.232.0.204/</a><br><strong>Haystack Framework</strong><br><a href="https://github.com/deepset-ai/haystack">https://github.com/deepset-ai/haystack</a><br>Haystack is an end-to-end framework that enables you to build powerful and production-ready pipelines for different search use cases. Whether you want to perform Question Answering or semantic document search, you can use the State-of-the-Art NLP models in Haystack to provide unique search experiences and allow your users to query in natural language. Haystack is built in a modular fashion so that you can combine the best technology from other open-source projects like Huggingface’s Transformers, Elasticsearch, or Milvus.<br><a href="https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html">https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html</a><br><strong>CORD-19: COVID-19 Open Research Dataset</strong><br>CORD-19 is a free resource of tens of thousands of scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses for use by the global research community.</p>]]></content>
      
      
      <categories>
          
          <category> projects </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Q&amp;A System </tag>
            
            <tag> Covid19 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How Does Chinese Segmentation Strategy Effect on Sentiment Analysis of Short Text?</title>
      <link href="/2021/08/26/chinese-seg/"/>
      <url>/2021/08/26/chinese-seg/</url>
      
        <content type="html"><![CDATA[<p><img src="images/chinese-seg.png" alt="cover"></p><p>In term of Chinese natural language processing, it exits one particular problem that how to choose the strategy of word segmentation, which commonly includes char-based and word-based. Targeted at sentiment analysis of short text comparing with long text, the word-based segmentation faces the other problem that there are the more ambiguous or unregistered words in context of short text. The feature extraction done by the different Chinese Word Segmentation impact the statistic distribution of features, and further the accuracy of sentiment analysis. This paper evaluates five Chinese segmentation strategy effect on Sentiment Analysis of Short Text.  We chose two word-based Chinese Word Segmentation (CWS), and three char-based n-gram, then transformed Bag-of-Word (BOW) to Vector Space Model (VSM) which finally was fed into several classifiers to predict sentiment polarity of short text. To reduce the impact of corpora, the study is based a collection of five public corpora.</p><p>Published in: 2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML)</p><p>DOI: 10.1109/SEAI52285.2021.9477550</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Sentiment Analysis </tag>
            
            <tag> Chinese Segmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leveraging Zipf’s Law to Analyze Statistical Distribution of Chinese Corpus</title>
      <link href="/2021/07/12/leveraging-Zipf/"/>
      <url>/2021/07/12/leveraging-Zipf/</url>
      
        <content type="html"><![CDATA[<p><img src="images/zipf.png" alt="cover"></p><p>In  term of  Chinese  natural  language  processing,  it exits  one  particular  problem  that  how  to  choose  the  strategy  of word  segmentation,  which  commonly  includes  char-based  and word-based.   Targeted   at   sentiment   analysis   of   short   text comparing with long text, the word-based segmentation faces the other problem that there are the more ambiguous or unregistered words in context of short text. The feature extraction done by the different   Chinese   Word   Segmentation   impact   the   statistic distribution  of  features,  and  further the  accuracy  of  sentiment analysis. This paper evaluates five Chinese segmentation strategy effect on Sentiment Analysis of Short Text.  We chose two word-based Chinese Word Segmentation (CWS), and three char-based n-gram and made usage of Zipf’s law to quantify and present the result of word segmentation.</p><p>Published in: 2021 IEEE International Conference on Software Engineering and Artificial Intelligence (SEAI)</p><p>DOI: 10.1109/SEAI52285.2021.9477550</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Chinese Segmentation </tag>
            
            <tag> Zipf </tag>
            
            <tag> Feature extraction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Showing History Trading Record of the Sample Companies with Graph</title>
      <link href="/2021/03/26/graph-trade/"/>
      <url>/2021/03/26/graph-trade/</url>
      
        <content type="html"><![CDATA[<p>As the data accessible is growing exponentially, the unstructured information has become the most common and main resource for decision makers. News, one of the most basic resource containing rich information covers from the company reports to market dynamics, has been regarded as one of the most important information resources. However, the richness of information in the huge volume of news also leads to the difficulty for the managers to get the key information benefit for their decisions, for which the processing on unstructured information is crucial and fundamental. This paper describes the establishment of a Chinese corpus for researches on financial entity recognition and financial relation extraction based on a large financial news data set. We propose a mixed pattern with POS tagging (Part of Speech Tagging) and BIES (Begin, Inside, End, Single) annotation for Generating quadruples (entity1, entity2, relation, text) from unstructured text. To the best of our knowledge this is the first attempt at extracting financial relation concepts. The average accuracy that was achieved by mixed pattern was (88.88%) by manually verification on random sampling dataset. Evaluation of the corpus gives good results and can be used for finance knowledge extraction.<br><strong>Published in: 2020 3rd International Conference on Artificial Intelligence and Big Data (ICAIBD)</strong><br><strong>DOI: 10.1109/ICAIBD49809.2020.9137442</strong></p><h2 id="可视化展示"><a href="#可视化展示" class="headerlink" title="可视化展示"></a>可视化展示</h2><div id="d3-example"></div><style>.node {stroke: #fff; stroke-width: 1.5px;}.link {stroke: #999; stroke-opacity: .9;}</style><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="d3" src="https://d3js.org/d3.v3.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script type="text/javascript">require.config({paths:    {d3: "https://d3js.org/d3.v3.min"}});require(["d3"], function(d3) {  // The code in this block is executed when the  // d3.js library has been loaded.  // First, we specify the size of the canvas  // containing the visualization (size of the  // <div> element).  var width = 900, height = 600;  // We create a color scale.  var color = d3.scale.category10();  // We create a force-directed dynamic graph layout.  var force = d3.layout.force()    .charge(-120)    .linkDistance(30)    .size([width, height]);  // In the <div> element, we create a <svg> graphic  // that will contain our interactive visualization.  var svg = d3.select("#d3-example").select("svg")  if (svg.empty()) {    svg = d3.select("#d3-example").append("svg")          .attr("width", width)          .attr("height", height);  }  // We load the JSON file.  d3.json("https://raw.githubusercontent.com/kgraphx/dataset/master/json/trade_graph.json", function(error, graph) {    force.nodes(graph.nodes)      .links(graph.links)      .start();        // We create a <line> SVG element for each link    // in the graph.    var link = svg.selectAll(".link")      .data(graph.links)      .enter().append("line")      .attr("class", "link");        // We create a <circle> SVG element for each node    // in the graph, and we specify a few attributes.    var node = svg.selectAll(".node")      .data(graph.nodes)      .enter().append("circle")      .attr("class", "node")      .attr("r", 5)  // radius      .style("fill", function(d) {         // The node color depends on the club.         return color(d.size);      })      .call(force.drag);        // The name of each node is the node number.    node.append("title")        .text(function(d) { return d.name; });        // We bind the positions of the SVG elements    // to the positions of the dynamic force-directed    // graph, at each time step.    force.on("tick", function() {      link.attr("x1", function(d){return d.source.x})          .attr("y1", function(d){return d.source.y})          .attr("x2", function(d){return d.target.x})          .attr("y2", function(d){return d.target.y});          node.attr("cx", function(d){return d.x})          .attr("cy", function(d){return d.y});    });  });});</script>]]></content>
      
      
      <categories>
          
          <category> projects </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kownledge Graph </tag>
            
            <tag> Trading Record </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Performance and Scalability Testing Strategy Based on Kubemark</title>
      <link href="/2019/05/30/kubemark/"/>
      <url>/2019/05/30/kubemark/</url>
      
        <content type="html"><![CDATA[<p><img src="images/kubemark.png" alt="cover"></p><p>The technology of container orchestration dramatically speeds up the extension of applications architected on microservices. As the complexity of those applications continues to increase, the orchestration system needs to resolve performance challenge to deploy thousands of coexisting applications to work cooperatively, and to reach the requirements of efficiency and scalability of microservices architectures. The Kubernetes is an open source project to implement container orchestration, and more popular than the others. For performance testing, the Kubernetes provides Kubemark as a deployment tool, which can simulate a large- scale Kubenetes clusters. Kubemark supports the performance evaluation of cluster scale much larger than the real cluster scale. This paper addresses performance issues of microservices structure, describes the architecture of Kubernetes to implement schedule of resource, and finally proposes a method of performance testing with Kubemark.</p><p>2019 IEEE 4th International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)<br>DOI: 10.1109/ICCCBDA.2019.8725658</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Microservices performance </tag>
            
            <tag> Kubemark </tag>
            
            <tag> Kubernet </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
